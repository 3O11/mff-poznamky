\documentclass[../main.tex]{subfiles}

%{definition}{Definice}
%{example}{Příklad}
%{intuition}{Intuice}
%{remark}{Poznámka}
%{consequence}{Důsledek}
%{observation}{Pozorování}

\begin{document}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Třetí přednáška}

\begin{definition}[Distribuční funkce]
    Distribuční funkce (cumulative distribution function, CDF) n.v. X
    je funkce
    \[F_X(x) := P(X\leq x) = P(\{\omega \in \Omega : X(\omega) \leq x\}).\]
    \begin{enumerate}
        \item $F_X$ je neklesajíci funkce
        \item $lim_{x \rightarrow -\infty} F_X(x) = 0$
        \item $lim_{x \rightarrow +\infty} F_X(x) = 1$
        \item $F_X$ je zprava spojitá
    \end{enumerate}
\end{definition}

\begin{example}
    $X = \{0$ s pravděpodobností $\frac{1}{2}, 1$ s psravděpodobností $\frac{1}{2}\}$
\end{example}
\begin{proof}
    $F_X$ je neklesajíci funkce\\

    $x<y \implies P(X\leq x) \leq P(X\leq y)$\\
    protože $A = {\omega : X(\omega) \leq x}$,\\
    $B = {\omega : X(\omega) \leq y}$, pak\\
    $A\subseteq B \implies P(A) \leq P(B)$
\end{proof}\\
\begin{proof}
    $\lim_{x\rightarrow +\infty} F_X(x) = 1$\\

    $A_n = {X\leq n};$ platí $A_1 \subseteq A_2 \subseteq \dots$\\
    Takže $\bigcup^\infty_{n=1} A_n = \Omega$, podle véty o spojitosti pak\\
    \[P(\Omega) = \lim_{n\rightarrow \infty} P(A_n) = \lim_{n\rightarrow \infty} F_X(n)\]
\end{proof}\\
druhá limita obdobně

\begin{definition}[Bernoulliho/alternativní rozdělení] {\color{white} x}
    \begin{enumerate}
        \item $X = $ počet orlů při jednom hodu nespravedlivou mincí.
        \item Značíme $X \sim Bern(p)$. Někdy se značí $Alt(p)$.
    \end{enumerate}

    \begin{enumerate}
        \item Dáno $p \in [0,1]$.
        \item $p_X(1)=p$
        \item $p_X(0) = 1 - p$
        \item $p_X(k) = 0$ pro $k \neq 0,1$
    \end{enumerate}

    \begin{enumerate}
        \item Pro libovolný jev $A \in \mathcal{F}$ definujeme \textit{indikátorovou} n.v. $I_A$:
        \item $I_A(\omega) = 1$ pokud $\omega \in A, I_A(\omega) = 0$ jinak.
        \item $I_A \sim  Bern(P(A))$.
    \end{enumerate}
\end{definition}

\begin{definition} {\color{white} x}
    \begin{enumerate}
        \item $X = $ počet orlů při $n$ hodech nespravedlivou mincí.
        \item Dáno $p \in [0,1] - $ pravděpodobnost orla při jednom hodu.
        \item Značíme $X \sim Bin(n,p)$. 
    \end{enumerate}
    \begin{enumerate}
        \item $X = \sum^n_{i=1}X_i$ pro nezávislé n.v. $X_1,\dots X_n \sim Bern(p)$.
        \item $p_X(k) = P(X = k) = \binom{n}{k}p^k(1-p)^{n-k}$ pro $k\in {0,1,\dots n}$.
    \end{enumerate}
    \[\sum^n_{k=1}\binom{n}{k}p^k(1-p)^{n-k} = 1\]
    \[(p + (1-p))^n = 1^n = 1\]
\end{definition}

\begin{definition}[Hypergeometrické rozdělení] {\color{white} x}
    \begin{enumerate}
        \item $X = $ počet vytažených červených míčku při $n$ tazích, v osudí je 
        $K$ červených z $N$ celkových míčků
        \item Dáno $n,N,K$.
        \item Značíme $X \sim Hyper(N,K,n)$.
        \item $p_X(k) = P(X = k) = \frac{\binom{K}{k}\binom{N-K}{n-k}}{\binom{N}{n}}$
    \end{enumerate}
\end{definition}

\begin{definition}[Poissonovo rozdělení (poasón)] {\color{white} x}

    \begin{enumerate}
        \item Značíme $X \sim Pois(\lambda)$.
        \item Dáno reálné $\lambda > 0$.
        \item $p_X(k) = \frac{\lambda^k}{k!}e^{-\lambda}$
        \item $Pois(\lambda)$ je limitou $Bin(n,\lambda/n)$ \dots $\sim X_n$ \dots $\lambda$ pevné
        \item $X$ popisuje např. počet emailů, které dostaneme za jednu hodinu.
    \end{enumerate}

    chceme $\sum \frac{\lambda^k}{k!}e^{-1} = 1$
    \[e^\lambda =  \sum^\infty_{k=0} \frac{\lambda^k}{k!}\]

    \[P(X_n = k) = \binom{n}{k}\left(\frac{\lambda}{n}\right)^k\left(1-\frac{\lambda}{n}\right)^{n-k} =\]
    \[=\frac{n(n-1)\dots (n-k+1)}{k!} \frac{\lambda^k}{n^k} \left(1-\frac{1}{n}\right)^n \left(1-\frac{\lambda}{n}\right)^{-k}=\]
    \[ = \frac{\lambda^k}{k!}e^{-\lambda}\]
\end{definition}

\begin{remark}[Poissonovo paradigma]

    $A_1,\dots A_n$ jsou (skoro-)nezávislé jevy s $P(A_i) = p_i$,
    $\lambda = \sum_j p_j$. Nechť $n$ je velké, každé z $p_i$ malé. Pak přibližně platí
    \[\sum^n_{i=1}I_{A_i} \sim Pois(\lambda)\]
\end{remark}

\begin{definition}[Geometrické rozdělení] {\color{white} x}

    \begin{enumerate}
        \item $X =$ kolikátým hodem mincí padl první orel.
        \item Značíme $X \sim Geom(p)$.
        \item Dáno $p\in [0,1]$.
        \item $p_X(k) = (1-p)^{k-1}p,$ pro $k=1,2,\dots$
        \item Někdy se tomuto rozdělení říká posunuté geometrické, a za normální geometrické
        se považuje rozdělení $X-1$, t.j. počet neúspěšných hodů.
    \end{enumerate}
    \begin{proof}
        chceme $\sum (1-p)^{k-1}p = 1$
        \[= \frac{(1-p)^{0}p}{1- (1-p)} = \frac{p}{p} = 1\]
    \end{proof}
\end{definition}
\begin{definition}[Střední hodnota]
    
    Pokud $X$ je diskrétní n.v., tak její střední hodnota (expectation) je označovaná $\mathbb{E}(X)$ a definovaná
    \[\mathbb{E}(X) = \sum_{x\in Im(X)}x \times P(X=x),\]
    pokud součet má smysl.
    
    Nechť $X$ je definovaná na diskrétním prostoru $(\Omega, \mathcal{F},P)$. Pak střední hodnotu lze také definovat
    \[\mathbb{E}(X) = \sum_{\omega \in \Omega} X(\omega)P({\omega}).\]
    ... vážený průměr 
    \begin{proof}
        dk., že obě definice souhlasí.
        \[\sum_{x\in Im(X(\omega))} \sum_{\omega \in \Omega} X(\omega) P({\omega}) = \sum_{x\in Im(X)}(x\times P({\omega \in \Omega : X(\omega) = x}))\]
    \end{proof}
\end{definition}
\begin{definition}[Rozptyl]

    Rozptyl(variace) n.v. $X$ nazveme číslo $\mathbb{E}((X-\mathbb{E}X)^2)$.\\
    Značíme jej $var(X)$

    \begin{theorem}
    \[var(X) = \mathbb{E}(X^2) - \mathbb{E}(X)^2\]
    \end{theorem}
\end{definition}
\begin{definition}[LOTUS (Law of The Unconscious Statistist)]

    Pro reálnou funkci $g$ a diskrtétni n.v. $X$ je $Y = g(X)$ také diskrétní n.v.
\end{definition}

\begin{theorem}[LOTUS]
    Pokud $X$ je diskrétní n.v. a $g$ reálná funkce, tak 
    \[\mathbb{E}(g(X)) = \sum_{x\in Im(X)}g(x)P(X=x)\]
    pokud součet má smysl.
\end{theorem}
\begin{proof}\\
    $Y = g(X)$
    \[\mathbb{E}Y = \sum_{y\in Y} y\times P(Y=y) \text{... definice}\]
    \[= \sum_{y \in Y} \sum_{x\in Im(X)}g(x) P(X=x)\]
    \[= \sum_{x\in Im(X)} g(x) P(X=x)\]
\end{proof}

\end{document}
